{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# âœ… ×©×œ×‘ 0: ×”×ª×§× ×ª YOLOX (×œ×œ× onnx-simplifier)\n",
        "!git clone https://github.com/Megvii-BaseDetection/YOLOX\n",
        "%cd YOLOX\n",
        "!sed -i '/onnx-simplifier/d' requirements.txt\n",
        "!pip install -r requirements.txt\n",
        "!pip install -v -e .\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Om3HVe2xo9wM",
        "outputId": "ee6b8a22-76b2-428e-e6ee-5a39160dee2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'YOLOX'...\n",
            "remote: Enumerating objects: 1928, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 1928 (delta 2), reused 0 (delta 0), pack-reused 1916 (from 2)\u001b[K\n",
            "Receiving objects: 100% (1928/1928), 7.55 MiB | 12.25 MiB/s, done.\n",
            "Resolving deltas: 100% (1148/1148), done.\n",
            "/content/YOLOX\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (2.0.2)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (2.6.0+cu124)\n",
            "Requirement already satisfied: opencv_python in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (4.11.0.86)\n",
            "Collecting loguru (from -r requirements.txt (line 5))\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (4.67.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (0.21.0+cu124)\n",
            "Collecting thop (from -r requirements.txt (line 8))\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting ninja (from -r requirements.txt (line 9))\n",
            "  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (0.9.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (5.9.5)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (2.18.0)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (2.0.8)\n",
            "Collecting onnx>=1.13.0 (from -r requirements.txt (line 17))\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->-r requirements.txt (line 3)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->-r requirements.txt (line 3)) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->-r requirements.txt (line 3)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->-r requirements.txt (line 3)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->-r requirements.txt (line 3)) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.7->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.7->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.7->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.7->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.7->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.7->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.7->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.7->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.7->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->-r requirements.txt (line 3)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->-r requirements.txt (line 3)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->-r requirements.txt (line 3)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.7->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->-r requirements.txt (line 3)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->-r requirements.txt (line 3)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.7->-r requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->-r requirements.txt (line 7)) (11.2.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 12)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 12)) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 12)) (3.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 12)) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 12)) (5.29.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 12)) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 12)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 12)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 12)) (3.1.3)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pycocotools>=2.0.2->-r requirements.txt (line 16)) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->-r requirements.txt (line 16)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->-r requirements.txt (line 16)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->-r requirements.txt (line 16)) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->-r requirements.txt (line 16)) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->-r requirements.txt (line 16)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->-r requirements.txt (line 16)) (2.9.0.post0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 12)) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ninja, loguru, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, thop\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed loguru-0.7.3 ninja-1.11.1.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 onnx-1.17.0 thop-0.1.1.post2209072238\n",
            "Using pip 24.1.2 from /usr/local/lib/python3.11/dist-packages/pip (python 3.11)\n",
            "Obtaining file:///content/YOLOX\n",
            "  Running command python setup.py egg_info\n",
            "  /usr/local/lib/python3.11/dist-packages/setuptools/__init__.py:94: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
            "  !!\n",
            "\n",
            "          ********************************************************************************\n",
            "          Requirements should be satisfied by a PEP 517 installer.\n",
            "          If you are using pip, you can try `pip install --use-pep517`.\n",
            "          ********************************************************************************\n",
            "\n",
            "  !!\n",
            "    dist.fetch_build_eggs(dist.setup_requires)\n",
            "  running egg_info\n",
            "  creating /tmp/pip-pip-egg-info-9istaj4i/yolox.egg-info\n",
            "  writing /tmp/pip-pip-egg-info-9istaj4i/yolox.egg-info/PKG-INFO\n",
            "  writing dependency_links to /tmp/pip-pip-egg-info-9istaj4i/yolox.egg-info/dependency_links.txt\n",
            "  writing requirements to /tmp/pip-pip-egg-info-9istaj4i/yolox.egg-info/requires.txt\n",
            "  writing top-level names to /tmp/pip-pip-egg-info-9istaj4i/yolox.egg-info/top_level.txt\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-9istaj4i/yolox.egg-info/SOURCES.txt'\n",
            "  reading manifest file '/tmp/pip-pip-egg-info-9istaj4i/yolox.egg-info/SOURCES.txt'\n",
            "  reading manifest template 'MANIFEST.in'\n",
            "  warning: no files found matching '*.cu' under directory 'yolox'\n",
            "  warning: no files found matching '*.cuh' under directory 'yolox'\n",
            "  warning: no files found matching '*.cc' under directory 'yolox'\n",
            "  adding license file 'LICENSE'\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-9istaj4i/yolox.egg-info/SOURCES.txt'\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from yolox==0.3.0) (2.0.2)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.11/dist-packages (from yolox==0.3.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: opencv_python in /usr/local/lib/python3.11/dist-packages (from yolox==0.3.0) (4.11.0.86)\n",
            "Requirement already satisfied: loguru in /usr/local/lib/python3.11/dist-packages (from yolox==0.3.0) (0.7.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from yolox==0.3.0) (4.67.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from yolox==0.3.0) (0.21.0+cu124)\n",
            "Requirement already satisfied: thop in /usr/local/lib/python3.11/dist-packages (from yolox==0.3.0) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from yolox==0.3.0) (1.11.1.4)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from yolox==0.3.0) (0.9.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from yolox==0.3.0) (5.9.5)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from yolox==0.3.0) (2.18.0)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from yolox==0.3.0) (2.0.8)\n",
            "Requirement already satisfied: onnx>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from yolox==0.3.0) (1.17.0)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx>=1.13.0->yolox==0.3.0) (5.29.4)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pycocotools>=2.0.2->yolox==0.3.0) (3.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->yolox==0.3.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->yolox==0.3.0) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->yolox==0.3.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->yolox==0.3.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->yolox==0.3.0) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->yolox==0.3.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->yolox==0.3.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->yolox==0.3.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->yolox==0.3.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->yolox==0.3.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->yolox==0.3.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->yolox==0.3.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->yolox==0.3.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->yolox==0.3.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->yolox==0.3.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->yolox==0.3.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->yolox==0.3.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->yolox==0.3.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->yolox==0.3.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->yolox==0.3.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.7->yolox==0.3.0) (1.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->yolox==0.3.0) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->yolox==0.3.0) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->yolox==0.3.0) (3.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard->yolox==0.3.0) (24.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->yolox==0.3.0) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard->yolox==0.3.0) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->yolox==0.3.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->yolox==0.3.0) (3.1.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->yolox==0.3.0) (11.2.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->yolox==0.3.0) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->yolox==0.3.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->yolox==0.3.0) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->yolox==0.3.0) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->yolox==0.3.0) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->yolox==0.3.0) (2.9.0.post0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard->yolox==0.3.0) (3.0.2)\n",
            "Installing collected packages: yolox\n",
            "  Running setup.py develop for yolox\n",
            "    Running command python setup.py develop\n",
            "    /usr/local/lib/python3.11/dist-packages/setuptools/__init__.py:94: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
            "    !!\n",
            "\n",
            "            ********************************************************************************\n",
            "            Requirements should be satisfied by a PEP 517 installer.\n",
            "            If you are using pip, you can try `pip install --use-pep517`.\n",
            "            ********************************************************************************\n",
            "\n",
            "    !!\n",
            "      dist.fetch_build_eggs(dist.setup_requires)\n",
            "    running develop\n",
            "    /usr/local/lib/python3.11/dist-packages/setuptools/command/develop.py:41: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "    !!\n",
            "\n",
            "            ********************************************************************************\n",
            "            Please avoid running ``setup.py`` and ``easy_install``.\n",
            "            Instead, use pypa/build, pypa/installer or other\n",
            "            standards-based tools.\n",
            "\n",
            "            See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "            ********************************************************************************\n",
            "\n",
            "    !!\n",
            "      easy_install.initialize_options(self)\n",
            "    /usr/local/lib/python3.11/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "    !!\n",
            "\n",
            "            ********************************************************************************\n",
            "            Please avoid running ``setup.py`` directly.\n",
            "            Instead, use pypa/build, pypa/installer or other\n",
            "            standards-based tools.\n",
            "\n",
            "            See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "            ********************************************************************************\n",
            "\n",
            "    !!\n",
            "      self.initialize_options()\n",
            "    running egg_info\n",
            "    creating yolox.egg-info\n",
            "    writing yolox.egg-info/PKG-INFO\n",
            "    writing dependency_links to yolox.egg-info/dependency_links.txt\n",
            "    writing requirements to yolox.egg-info/requires.txt\n",
            "    writing top-level names to yolox.egg-info/top_level.txt\n",
            "    writing manifest file 'yolox.egg-info/SOURCES.txt'\n",
            "    reading manifest file 'yolox.egg-info/SOURCES.txt'\n",
            "    reading manifest template 'MANIFEST.in'\n",
            "    warning: no files found matching '*.cu' under directory 'yolox'\n",
            "    warning: no files found matching '*.cuh' under directory 'yolox'\n",
            "    warning: no files found matching '*.cc' under directory 'yolox'\n",
            "    adding license file 'LICENSE'\n",
            "    writing manifest file 'yolox.egg-info/SOURCES.txt'\n",
            "    running build_ext\n",
            "    building 'yolox.layers.fast_cocoeval' extension\n",
            "    creating /content/YOLOX/build/temp.linux-x86_64-cpython-311/yolox/layers/cocoeval\n",
            "    Emitting ninja build file /content/YOLOX/build/temp.linux-x86_64-cpython-311/build.ninja...\n",
            "    Compiling objects...\n",
            "    Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "    [1/1] c++ -MMD -MF /content/YOLOX/build/temp.linux-x86_64-cpython-311/yolox/layers/cocoeval/cocoeval.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -Iyolox/layers/cocoeval -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/include/python3.11 -c -c /content/YOLOX/yolox/layers/cocoeval/cocoeval.cpp -o /content/YOLOX/build/temp.linux-x86_64-cpython-311/yolox/layers/cocoeval/cocoeval.o -O3 -std=c++14 -g -Wno-reorder -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fast_cocoeval -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "    creating build/lib.linux-x86_64-cpython-311/yolox/layers\n",
            "    x86_64-linux-gnu-g++ -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -shared -Wl,-O1 -Wl,-Bsymbolic-functions /content/YOLOX/build/temp.linux-x86_64-cpython-311/yolox/layers/cocoeval/cocoeval.o -L/usr/local/lib/python3.11/dist-packages/torch/lib -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-cpython-311/yolox/layers/fast_cocoeval.cpython-311-x86_64-linux-gnu.so\n",
            "    copying build/lib.linux-x86_64-cpython-311/yolox/layers/fast_cocoeval.cpython-311-x86_64-linux-gnu.so -> yolox/layers\n",
            "    Creating /usr/local/lib/python3.11/dist-packages/yolox.egg-link (link to .)\n",
            "    Adding yolox 0.3.0 to easy-install.pth file\n",
            "\n",
            "    Installed /content/YOLOX\n",
            "Successfully installed yolox-0.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# ×œ×”×¨×™×¥ ×‘×ª×™×§×™×™×ª /content/YOLOX\n",
        "cd /content/YOLOX\n",
        "set -e\n",
        "\n",
        "echo \"ğŸ”§  Patching trainer.py â€“ disable L1 once and for all â€¦\"\n",
        "\n",
        "# 1ï¸âƒ£  ××‘×˜×œ×™× ××ª ×”×”×“×¤×¡×” + ×”×ª× ××™ (×¢× ××• ×‘×œ×™ ×¨×•×•×— ××—×¨×™ ×”×—×¦×™×)\n",
        "sed -i -E \\\n",
        "  -e 's/self\\.logger\\.info\\(\"---> ?Add additional L1 loss now!\"\\)/# L1 disabled â€“ no log/' \\\n",
        "  -e 's/if +self\\.exp\\.add_l1_loss/if False  # patched: never add L1/' \\\n",
        "  yolox/core/trainer.py\n",
        "\n",
        "# 2ï¸âƒ£  ××—×œ×™×¤×™× ×›×œ self.exp.add_l1_loss â†’ False (×©×œ× ×™×•×¤×¢×œ ×‘×©×•× ××§×•×)\n",
        "sed -i 's/self\\.exp\\.add_l1_loss/False/g' yolox/core/trainer.py\n",
        "\n",
        "echo \"âœ…  trainer.py patched â€“ L1 loss ××‘×•×˜×œ ×œ×—×œ×•×˜×™×Ÿ\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvbtwpfQ4DWO",
        "outputId": "59184514-2e34-40c3-fb25-e352387b019c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patching trainer.py ...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect, textwrap, yolox.core.trainer as T\n",
        "print(textwrap.dedent(\"\\n\".join(\n",
        "    l for l in inspect.getsource(T.Trainer).splitlines()\n",
        "    if 'add_l1_loss' in l or 'logger.info(\"--->' in l\n",
        ")))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gePrBO49GRVO",
        "outputId": "7fcecc6c-2628-4f47-9dac-fc6d2126191e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logger.info(\"---> start train epoch{}\".format(self.epoch + 1))\n",
            "    logger.info(\"--->No mosaic aug now!\")\n",
            "    logger.info(\"--->Add additional L1 loss now!\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… ×©×œ×‘ 1: ×”×¢×œ××ª ×§×•×‘×¥ ZIP ×•×—×™×œ×•×¥\n",
        "from google.colab import files\n",
        "import zipfile, os\n",
        "\n",
        "uploaded = files.upload()\n",
        "zip_filename = next(iter(uploaded))\n",
        "extract_path = \"datasets/drone_ir\"\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "# ×©×™× ×•×™ ×©× ×ª×™×§×™×” ×¢× ×¨×•×•×—×™× ×× ×¦×¨×™×š\n",
        "old_name = os.path.join(extract_path, \"Drone Detection.v1i.yolov5pytorch\")\n",
        "new_name = os.path.join(extract_path, \"drone_dataset\")\n",
        "if os.path.exists(old_name):\n",
        "    os.rename(old_name, new_name)\n",
        "\n",
        "print(f\"âœ… ×”×§×•×‘×¥ {zip_filename} ×—×•×œ×¥ ×œ×ª×•×š: {new_name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "MjLkww2YpBdf",
        "outputId": "739ee063-7d4a-4684-df89-a4ec8aaf24db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6d0456a4-51ad-4754-b107-f71097ef92a8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6d0456a4-51ad-4754-b107-f71097ef92a8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Drone Detection.v1i.yolov5pytorch (2).zip to Drone Detection.v1i.yolov5pytorch (2).zip\n",
            "âœ… ×”×§×•×‘×¥ Drone Detection.v1i.yolov5pytorch (2).zip ×—×•×œ×¥ ×œ×ª×•×š: datasets/drone_ir/drone_dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… ×©×œ×‘ 2: ×™×¦×™×¨×ª train.txt, val.txt, classes.txt\n",
        "import glob\n",
        "\n",
        "base_path = \"datasets/drone_ir/drone_dataset\"\n",
        "train_images_dir = os.path.join(base_path, \"train\", \"images\")\n",
        "val_images_dir = os.path.join(base_path, \"valid\", \"images\")\n",
        "\n",
        "train_imgs = glob.glob(os.path.join(train_images_dir, \"*.jpg\"))\n",
        "val_imgs = glob.glob(os.path.join(val_images_dir, \"*.jpg\"))\n",
        "\n",
        "with open(os.path.join(base_path, \"train.txt\"), \"w\") as f:\n",
        "    f.write(\"\\n\".join(train_imgs))\n",
        "\n",
        "with open(os.path.join(base_path, \"valid.txt\"), \"w\") as f:\n",
        "    f.write(\"\\n\".join(val_imgs))\n",
        "\n",
        "with open(os.path.join(base_path, \"classes.txt\"), \"w\") as f:\n",
        "    f.write(\"droneIR\")\n",
        "\n",
        "print(\"âœ… × ×•×¦×¨×• ×”×§×‘×¦×™× train.txt, valid.txt, classes.txt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BX6sgILtpX_P",
        "outputId": "cf5d2df5-fa46-4473-de0c-075a3c12262a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… × ×•×¦×¨×• ×”×§×‘×¦×™× train.txt, valid.txt, classes.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… Exp ×—×“×© â€“ ××™×Ÿ Evaluator ×•××™×Ÿ L1â€‘loss\n",
        "import os, textwrap\n",
        "from pathlib import Path\n",
        "\n",
        "EXP_PATH = Path(\"exps/example/custom\")\n",
        "EXP_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "exp_code = textwrap.dedent(\"\"\"\n",
        "    import os\n",
        "    from yolox.exp import Exp as BaseExp\n",
        "\n",
        "    class Exp(BaseExp):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "            # --- ×‘×¡×™×¡ ---\n",
        "            self.num_classes  = 1\n",
        "            self.depth        = 0.33\n",
        "            self.width        = 0.5\n",
        "            self.input_size   = (640, 640)\n",
        "            self.test_size    = (640, 640)\n",
        "            self.exp_name     = \"yolox_drone\"\n",
        "            self.max_epoch    = 10\n",
        "\n",
        "            # --- ×‘×œ×™ evaluator ---\n",
        "            self.eval_interval = -1\n",
        "            self.no_eval       = True\n",
        "\n",
        "            # --- × ×ª×™×‘×™ Dataset ---\n",
        "            self.data_dir  = \"datasets/drone_ir/drone_dataset\"\n",
        "            self.train_ann = \"train\"\n",
        "            self.val_ann   = \"valid\"\n",
        "            self.classes   = [\"droneIR\"]\n",
        "\n",
        "            # --- ××•×’×× ×˜×¦×™×” ××™× ×™××œ×™×ª ---\n",
        "            self.enable_mixup = False\n",
        "            self.mosaic_prob  = 0.0\n",
        "            self.mixup_prob   = 0.0\n",
        "            self.hsv_prob     = 1.0\n",
        "            self.flip_prob    = 0.5\n",
        "            self.no_aug       = True\n",
        "\n",
        "            # --- Loss / LR ---\n",
        "            self.add_l1_loss   = False      # ×œ× ××¤×¢×™×œ×™× L1\n",
        "            self.warmup_epochs = 0\n",
        "\n",
        "            # --- NMS / confidence ---\n",
        "            self.test_conf = 0.01\n",
        "            self.nmsthre   = 0.65\n",
        "\n",
        "        # ---------- model ----------\n",
        "        def get_model(self):\n",
        "            # ××©×ª××©×™× ×‘××™××•×© ×‘×¨×™×¨×ªâ€‘×”××—×“×œ ×©×œ YOLOX\n",
        "            model = super().get_model()\n",
        "            # ××›×‘×™× ××ª L1â€‘loss ×××© ×‘×ª×•×š ×”×¨××©\n",
        "            if hasattr(model, \"head\") and hasattr(model.head, \"use_l1\"):\n",
        "                model.head.use_l1 = False\n",
        "            return model\n",
        "\n",
        "        # ---------- datasets ----------\n",
        "        def get_dataset(self, cache=False, cache_type=\"ram\"):\n",
        "            from yolox.data.data_augment import TrainTransform\n",
        "            from yolox.data.datasets.yolov5dataset import YOLOv5Dataset\n",
        "            return YOLOv5Dataset(\n",
        "                data_dir=self.data_dir,\n",
        "                name=self.train_ann,\n",
        "                img_size=self.input_size,\n",
        "                preproc=TrainTransform(\n",
        "                    max_labels=50,\n",
        "                    flip_prob=self.flip_prob,\n",
        "                    hsv_prob=self.hsv_prob,\n",
        "                ),\n",
        "                cache=cache,\n",
        "            )\n",
        "\n",
        "        def get_eval_dataset(self, **kwargs):\n",
        "            from yolox.data.data_augment import ValTransform\n",
        "            from yolox.data.datasets.yolov5dataset import YOLOv5Dataset\n",
        "            return YOLOv5Dataset(\n",
        "                data_dir=self.data_dir,\n",
        "                name=self.val_ann,\n",
        "                img_size=self.test_size,\n",
        "                preproc=ValTransform(),\n",
        "            )\n",
        "\"\"\")\n",
        "\n",
        "with open(EXP_PATH / \"yolox_drone.py\", \"w\") as f:\n",
        "    f.write(exp_code)\n",
        "\n",
        "print(\"âœ…  exps/example/custom/yolox_drone.py × ×›×ª×‘ â€“ head.use_l1=False, ××™×Ÿ Evaluator\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szaxV2UipcnI",
        "outputId": "6ae40603-3018-4ab5-cb67-3f144f238623"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ…  exps/example/custom/yolox_drone.py × ×›×ª×‘ â€“ head.use_l1=False, ××™×Ÿ Evaluator\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… ×™×¦×™×¨×ª YOLOv5Dataset ×¢× ×”×¤×•× ×§×¦×™×” pull_item + evaluate_detections ×©×œ×‘ 4\n",
        "!mkdir -p yolox/data/datasets\n",
        "\n",
        "dataset_code = '''\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class YOLOv5Dataset(Dataset):\n",
        "    def __init__(self, data_dir, name, img_size, preproc=None, cache=False):\n",
        "        cls_path = os.path.join(data_dir, \"classes.txt\")\n",
        "        with open(cls_path, \"r\") as f:\n",
        "            self.class_names = [c.strip() for c in f.readlines()]\n",
        "        self.num_classes = len(self.class_names)\n",
        "        self.img_size = img_size\n",
        "        self.preproc = preproc\n",
        "        self.input_dim = img_size\n",
        "\n",
        "        list_path = os.path.join(data_dir, f\"{name}.txt\")\n",
        "        with open(list_path, \"r\") as f:\n",
        "            self.img_files = [line.strip() for line in f.readlines()]\n",
        "\n",
        "        self.img_files = [\n",
        "            path if os.path.isabs(path) or path.startswith(data_dir) else os.path.join(data_dir, path)\n",
        "            for path in self.img_files\n",
        "        ]\n",
        "\n",
        "        self.label_files = []\n",
        "        for img_path in self.img_files:\n",
        "            base_path = os.path.dirname(img_path).replace(\"images\", \"labels\")\n",
        "            file_name = os.path.basename(img_path).replace(\".jpg\", \".txt\").replace(\".png\", \".txt\")\n",
        "            label_path = os.path.join(base_path, file_name)\n",
        "            self.label_files.append(label_path)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_files)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if isinstance(index, tuple):\n",
        "            index = index[0]\n",
        "        img, label, img_info, img_id = self.pull_item(index)\n",
        "        if self.preproc:\n",
        "            img, label = self.preproc(img, label, self.input_dim)\n",
        "        return img, label, img_info, img_id\n",
        "\n",
        "    def pull_item(self, index):\n",
        "        img_path = self.img_files[index]\n",
        "        label_path = self.label_files[index]\n",
        "\n",
        "        img = cv2.imread(img_path)\n",
        "        assert img is not None, f\"Image not found: {img_path}\"\n",
        "        height, width = img.shape[:2]\n",
        "\n",
        "        labels = []\n",
        "        if os.path.exists(label_path):\n",
        "            with open(label_path, \"r\") as f:\n",
        "                for line in f:\n",
        "                    parts = line.strip().split()\n",
        "                    if len(parts) == 5:\n",
        "                        cls, x, y, w, h = map(float, parts)\n",
        "                        labels.append([cls, x, y, w, h])\n",
        "        labels = np.array(labels, dtype=np.float32).reshape(-1, 5) if labels else np.zeros((0, 5), dtype=np.float32)\n",
        "\n",
        "        img_info = (height, width)\n",
        "        img_id = index\n",
        "\n",
        "        return img, labels, img_info, img_id\n",
        "\n",
        "    def evaluate_detections(self, all_boxes, save_dir):\n",
        "        print(\"âš ï¸ Warning: evaluation skipped (dummy implementation).\")\n",
        "        return 0.0, 0.0  # mAP50, mAP70\n",
        "'''\n",
        "\n",
        "with open(\"yolox/data/datasets/yolov5dataset.py\", \"w\") as f:\n",
        "    f.write(dataset_code)\n",
        "\n",
        "print(\"âœ… YOLOv5Dataset × ×•×¦×¨ ×‘×”×¦×œ×—×” ×¢× evaluate_detections ××“×•××”\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6_6pokgpfjz",
        "outputId": "d1251fbc-7fe4-4ad2-979f-98ebeb79b25d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… YOLOv5Dataset × ×•×¦×¨ ×‘×”×¦×œ×—×” ×¢× evaluate_detections ××“×•××”\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# ğŸ“ × ×ª×™×‘ ×œ×ª×™×§×™×™×ª ×”×“××˜×”×¡×˜ ×©×œ×š\n",
        "base_dir = \"datasets/drone_ir/drone_dataset\"\n",
        "\n",
        "# ğŸ§  × ×ª×™×‘×™× ×œ×¦×•×¨×š ×‘×“×™×§×”\n",
        "train_labels = os.path.join(base_dir, \"train\", \"labels\")\n",
        "valid_labels = os.path.join(base_dir, \"valid\", \"labels\")\n",
        "\n",
        "print(f\"ğŸ” Checking label folders in: {base_dir}\")\n",
        "\n",
        "# âœ… ×‘×“×™×§×” ×©×”×ª×§×™×•×ª ×§×™×™××•×ª\n",
        "if not os.path.isdir(train_labels):\n",
        "    print(f\"âŒ Label directory does not exist: {train_labels}\")\n",
        "    print(\"ğŸ›‘ Training aborted due to invalid label files.\")\n",
        "elif not os.path.isdir(valid_labels):\n",
        "    print(f\"âŒ Label directory does not exist: {valid_labels}\")\n",
        "    print(\"ğŸ›‘ Training aborted due to invalid label files.\")\n",
        "else:\n",
        "    print(\"âœ… Label folders found!\")\n",
        "\n",
        "    # ğŸš€ ×× ×”×›×•×œ ×ª×§×™×Ÿ â€“ × ×¨×™×¥ ××ª ×”××™××•×Ÿ\n",
        "    !python tools/train.py -f exps/example/custom/yolox_drone.py -d 1 -b 8 --fp16 -o\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nl2Mc8Ig0L3Q",
        "outputId": "f4245622-f136-4857-a108-1b364c06b486"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ” Checking label folders in: datasets/drone_ir/drone_dataset\n",
            "âœ… Label folders found!\n",
            "2025-05-08 14:15:37.950693: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1746713737.972353    1840 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1746713737.979422    1840 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "/content/YOLOX/yolox/core/trainer.py:47: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(enabled=args.fp16)\n",
            "\u001b[32m2025-05-08 14:15:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m132\u001b[0m - \u001b[1margs: Namespace(experiment_name='yolox_drone', name=None, dist_backend='nccl', dist_url=None, batch_size=8, devices=1, exp_file='exps/example/custom/yolox_drone.py', resume=False, ckpt=None, start_epoch=None, num_machines=1, machine_rank=0, fp16=True, cache=None, occupy=True, logger='tensorboard', opts=[])\u001b[0m\n",
            "\u001b[32m2025-05-08 14:15:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mexp value:\n",
            "â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••\n",
            "â”‚ keys              â”‚ values                            â”‚\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
            "â”‚ seed              â”‚ None                              â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ output_dir        â”‚ './YOLOX_outputs'                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ print_interval    â”‚ 10                                â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ eval_interval     â”‚ -1                                â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dataset           â”‚ None                              â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ num_classes       â”‚ 1                                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ depth             â”‚ 0.33                              â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ width             â”‚ 0.5                               â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ act               â”‚ 'silu'                            â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ data_num_workers  â”‚ 4                                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ input_size        â”‚ (640, 640)                        â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ multiscale_range  â”‚ 5                                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ data_dir          â”‚ 'datasets/drone_ir/drone_dataset' â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ train_ann         â”‚ 'train'                           â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ val_ann           â”‚ 'valid'                           â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ test_ann          â”‚ 'instances_test2017.json'         â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ mosaic_prob       â”‚ 0.0                               â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ mixup_prob        â”‚ 0.0                               â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ hsv_prob          â”‚ 1.0                               â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ flip_prob         â”‚ 0.5                               â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ degrees           â”‚ 10.0                              â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ translate         â”‚ 0.1                               â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ mosaic_scale      â”‚ (0.1, 2)                          â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ enable_mixup      â”‚ False                             â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ mixup_scale       â”‚ (0.5, 1.5)                        â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ shear             â”‚ 2.0                               â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ warmup_epochs     â”‚ 0                                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_epoch         â”‚ 10                                â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ warmup_lr         â”‚ 0                                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ min_lr_ratio      â”‚ 0.05                              â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ basic_lr_per_img  â”‚ 0.00015625                        â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ scheduler         â”‚ 'yoloxwarmcos'                    â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ no_aug_epochs     â”‚ 15                                â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ ema               â”‚ True                              â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ weight_decay      â”‚ 0.0005                            â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ momentum          â”‚ 0.9                               â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ save_history_ckpt â”‚ True                              â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ exp_name          â”‚ 'yolox_drone'                     â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ test_size         â”‚ (640, 640)                        â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ test_conf         â”‚ 0.01                              â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ nmsthre           â”‚ 0.65                              â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ no_eval           â”‚ True                              â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ classes           â”‚ ['droneIR']                       â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ no_aug            â”‚ True                              â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ add_l1_loss       â”‚ False                             â”‚\n",
            "â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›\u001b[0m\n",
            "\u001b[32m2025-05-08 14:15:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mModel Summary: Params: 8.94M, Gflops: 26.76\u001b[0m\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "\u001b[32m2025-05-08 14:15:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1minit prefetcher, this might take one minute or less...\u001b[0m\n",
            "/content/YOLOX/yolox/utils/metric.py:43: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)\n",
            "  x = torch.cuda.FloatTensor(256, 1024, block_mem)\n",
            "\u001b[32m2025-05-08 14:15:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1mTraining start...\u001b[0m\n",
            "\u001b[32m2025-05-08 14:15:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1m\n",
            "YOLOX(\n",
            "  (backbone): YOLOPAFPN(\n",
            "    (backbone): CSPDarknet(\n",
            "      (stem): Focus(\n",
            "        (conv): BaseConv(\n",
            "          (conv): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (dark2): Sequential(\n",
            "        (0): BaseConv(\n",
            "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (1): CSPLayer(\n",
            "          (conv1): BaseConv(\n",
            "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv2): BaseConv(\n",
            "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv3): BaseConv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (m): Sequential(\n",
            "            (0): Bottleneck(\n",
            "              (conv1): BaseConv(\n",
            "                (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (conv2): BaseConv(\n",
            "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (dark3): Sequential(\n",
            "        (0): BaseConv(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (1): CSPLayer(\n",
            "          (conv1): BaseConv(\n",
            "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv2): BaseConv(\n",
            "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv3): BaseConv(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (m): Sequential(\n",
            "            (0): Bottleneck(\n",
            "              (conv1): BaseConv(\n",
            "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (conv2): BaseConv(\n",
            "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "            (1): Bottleneck(\n",
            "              (conv1): BaseConv(\n",
            "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (conv2): BaseConv(\n",
            "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "            (2): Bottleneck(\n",
            "              (conv1): BaseConv(\n",
            "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (conv2): BaseConv(\n",
            "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (dark4): Sequential(\n",
            "        (0): BaseConv(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (1): CSPLayer(\n",
            "          (conv1): BaseConv(\n",
            "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv2): BaseConv(\n",
            "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv3): BaseConv(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (m): Sequential(\n",
            "            (0): Bottleneck(\n",
            "              (conv1): BaseConv(\n",
            "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (conv2): BaseConv(\n",
            "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "            (1): Bottleneck(\n",
            "              (conv1): BaseConv(\n",
            "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (conv2): BaseConv(\n",
            "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "            (2): Bottleneck(\n",
            "              (conv1): BaseConv(\n",
            "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (conv2): BaseConv(\n",
            "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (dark5): Sequential(\n",
            "        (0): BaseConv(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (1): SPPBottleneck(\n",
            "          (conv1): BaseConv(\n",
            "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (m): ModuleList(\n",
            "            (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
            "            (1): MaxPool2d(kernel_size=9, stride=1, padding=4, dilation=1, ceil_mode=False)\n",
            "            (2): MaxPool2d(kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False)\n",
            "          )\n",
            "          (conv2): BaseConv(\n",
            "            (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (2): CSPLayer(\n",
            "          (conv1): BaseConv(\n",
            "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv2): BaseConv(\n",
            "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv3): BaseConv(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (m): Sequential(\n",
            "            (0): Bottleneck(\n",
            "              (conv1): BaseConv(\n",
            "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (conv2): BaseConv(\n",
            "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
            "    (lateral_conv0): BaseConv(\n",
            "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (C3_p4): CSPLayer(\n",
            "      (conv1): BaseConv(\n",
            "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (conv2): BaseConv(\n",
            "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (conv3): BaseConv(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): BaseConv(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv2): BaseConv(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (reduce_conv1): BaseConv(\n",
            "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (C3_p3): CSPLayer(\n",
            "      (conv1): BaseConv(\n",
            "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (conv2): BaseConv(\n",
            "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (conv3): BaseConv(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): BaseConv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv2): BaseConv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (bu_conv2): BaseConv(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (C3_n3): CSPLayer(\n",
            "      (conv1): BaseConv(\n",
            "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (conv2): BaseConv(\n",
            "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (conv3): BaseConv(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): BaseConv(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv2): BaseConv(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (bu_conv1): BaseConv(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (C3_n4): CSPLayer(\n",
            "      (conv1): BaseConv(\n",
            "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (conv2): BaseConv(\n",
            "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (conv3): BaseConv(\n",
            "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): BaseConv(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv2): BaseConv(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (head): YOLOXHead(\n",
            "    (cls_convs): ModuleList(\n",
            "      (0-2): 3 x Sequential(\n",
            "        (0): BaseConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (1): BaseConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (reg_convs): ModuleList(\n",
            "      (0-2): 3 x Sequential(\n",
            "        (0): BaseConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (1): BaseConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (cls_preds): ModuleList(\n",
            "      (0-2): 3 x Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (reg_preds): ModuleList(\n",
            "      (0-2): 3 x Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (obj_preds): ModuleList(\n",
            "      (0-2): 3 x Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (stems): ModuleList(\n",
            "      (0): BaseConv(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (1): BaseConv(\n",
            "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (2): BaseConv(\n",
            "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (l1_loss): L1Loss()\n",
            "    (bcewithlog_loss): BCEWithLogitsLoss()\n",
            "    (iou_loss): IOUloss()\n",
            "  )\n",
            ")\u001b[0m\n",
            "/content/YOLOX/yolox/core/trainer.py:106: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=self.amp_training):\n",
            "\u001b[32m2025-05-08 14:15:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m218\u001b[0m - \u001b[1m---> start train epoch1\u001b[0m\n",
            "\u001b[32m2025-05-08 14:15:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m221\u001b[0m - \u001b[1m--->No mosaic aug now!\u001b[0m\n",
            "\u001b[32m2025-05-08 14:15:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m223\u001b[0m - \u001b[1m--->Add additional L1 loss now!\u001b[0m\n",
            "/content/YOLOX/yolox/models/yolo_head.py:474: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=False):\n",
            "\u001b[32m2025-05-08 14:15:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m270\u001b[0m - \u001b[1mepoch: 1/10, iter: 10/18, gpu mem: 13692Mb, mem: 3.2Gb, iter_time: 0.606s, data_time: 0.011s, total_loss: nan, iou_loss: 5.0, l1_loss: nan, conf_loss: 90.1, cls_loss: 0.0, lr: 6.250e-05, size: 640, ETA: 0:01:42\u001b[0m\n",
            "\u001b[32m2025-05-08 14:15:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m402\u001b[0m - \u001b[1mSave weights to ./YOLOX_outputs/yolox_drone\u001b[0m\n",
            "100% 4/4 [00:02<00:00,  1.93it/s]\n",
            "\u001b[32m2025-05-08 14:16:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.evaluators.coco_evaluator\u001b[0m:\u001b[36m259\u001b[0m - \u001b[1mEvaluate in main process...\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m381\u001b[0m - \u001b[1m\n",
            "Average forward time: 43.18 ms, Average NMS time: 0.39 ms, Average inference time: 43.57 ms\n",
            "\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m402\u001b[0m - \u001b[1mSave weights to ./YOLOX_outputs/yolox_drone\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m402\u001b[0m - \u001b[1mSave weights to ./YOLOX_outputs/yolox_drone\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m218\u001b[0m - \u001b[1m---> start train epoch2\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m221\u001b[0m - \u001b[1m--->No mosaic aug now!\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m223\u001b[0m - \u001b[1m--->Add additional L1 loss now!\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m270\u001b[0m - \u001b[1mepoch: 2/10, iter: 10/18, gpu mem: 13692Mb, mem: 3.3Gb, iter_time: 0.291s, data_time: 0.006s, total_loss: nan, iou_loss: 5.0, l1_loss: nan, conf_loss: 27.0, cls_loss: 0.0, lr: 6.250e-05, size: 512, ETA: 0:01:03\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m402\u001b[0m - \u001b[1mSave weights to ./YOLOX_outputs/yolox_drone\u001b[0m\n",
            "100% 4/4 [00:00<00:00,  5.57it/s]\n",
            "\u001b[32m2025-05-08 14:16:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.evaluators.coco_evaluator\u001b[0m:\u001b[36m259\u001b[0m - \u001b[1mEvaluate in main process...\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m381\u001b[0m - \u001b[1m\n",
            "Average forward time: 7.95 ms, Average NMS time: 0.34 ms, Average inference time: 8.29 ms\n",
            "\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m402\u001b[0m - \u001b[1mSave weights to ./YOLOX_outputs/yolox_drone\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m402\u001b[0m - \u001b[1mSave weights to ./YOLOX_outputs/yolox_drone\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m218\u001b[0m - \u001b[1m---> start train epoch3\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m221\u001b[0m - \u001b[1m--->No mosaic aug now!\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m223\u001b[0m - \u001b[1m--->Add additional L1 loss now!\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m270\u001b[0m - \u001b[1mepoch: 3/10, iter: 10/18, gpu mem: 13692Mb, mem: 3.2Gb, iter_time: 0.403s, data_time: 0.003s, total_loss: nan, iou_loss: 5.0, l1_loss: nan, conf_loss: 27.2, cls_loss: 0.0, lr: 6.250e-05, size: 768, ETA: 0:00:55\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m402\u001b[0m - \u001b[1mSave weights to ./YOLOX_outputs/yolox_drone\u001b[0m\n",
            "100% 4/4 [00:00<00:00,  4.98it/s]\n",
            "\u001b[32m2025-05-08 14:16:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.evaluators.coco_evaluator\u001b[0m:\u001b[36m259\u001b[0m - \u001b[1mEvaluate in main process...\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m381\u001b[0m - \u001b[1m\n",
            "Average forward time: 7.70 ms, Average NMS time: 0.72 ms, Average inference time: 8.42 ms\n",
            "\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m402\u001b[0m - \u001b[1mSave weights to ./YOLOX_outputs/yolox_drone\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m402\u001b[0m - \u001b[1mSave weights to ./YOLOX_outputs/yolox_drone\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m218\u001b[0m - \u001b[1m---> start train epoch4\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m221\u001b[0m - \u001b[1m--->No mosaic aug now!\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m223\u001b[0m - \u001b[1m--->Add additional L1 loss now!\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m270\u001b[0m - \u001b[1mepoch: 4/10, iter: 10/18, gpu mem: 13692Mb, mem: 3.3Gb, iter_time: 0.205s, data_time: 0.005s, total_loss: nan, iou_loss: 5.0, l1_loss: nan, conf_loss: 7.0, cls_loss: 0.0, lr: 6.250e-05, size: 512, ETA: 0:00:44\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m402\u001b[0m - \u001b[1mSave weights to ./YOLOX_outputs/yolox_drone\u001b[0m\n",
            "100% 4/4 [00:00<00:00,  5.63it/s]\n",
            "\u001b[32m2025-05-08 14:16:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.evaluators.coco_evaluator\u001b[0m:\u001b[36m259\u001b[0m - \u001b[1mEvaluate in main process...\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m381\u001b[0m - \u001b[1m\n",
            "Average forward time: 7.60 ms, Average NMS time: 0.33 ms, Average inference time: 7.93 ms\n",
            "\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m402\u001b[0m - \u001b[1mSave weights to ./YOLOX_outputs/yolox_drone\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m402\u001b[0m - \u001b[1mSave weights to ./YOLOX_outputs/yolox_drone\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m218\u001b[0m - \u001b[1m---> start train epoch5\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m221\u001b[0m - \u001b[1m--->No mosaic aug now!\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m223\u001b[0m - \u001b[1m--->Add additional L1 loss now!\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m270\u001b[0m - \u001b[1mepoch: 5/10, iter: 10/18, gpu mem: 13692Mb, mem: 3.2Gb, iter_time: 0.278s, data_time: 0.010s, total_loss: nan, iou_loss: 5.0, l1_loss: nan, conf_loss: 12.6, cls_loss: 0.0, lr: 6.250e-05, size: 768, ETA: 0:00:35\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m402\u001b[0m - \u001b[1mSave weights to ./YOLOX_outputs/yolox_drone\u001b[0m\n",
            "100% 4/4 [00:00<00:00,  6.02it/s]\n",
            "\u001b[32m2025-05-08 14:16:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.evaluators.coco_evaluator\u001b[0m:\u001b[36m259\u001b[0m - \u001b[1mEvaluate in main process...\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m381\u001b[0m - \u001b[1m\n",
            "Average forward time: 8.47 ms, Average NMS time: 0.49 ms, Average inference time: 8.96 ms\n",
            "\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m402\u001b[0m - \u001b[1mSave weights to ./YOLOX_outputs/yolox_drone\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m402\u001b[0m - \u001b[1mSave weights to ./YOLOX_outputs/yolox_drone\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m218\u001b[0m - \u001b[1m---> start train epoch6\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m221\u001b[0m - \u001b[1m--->No mosaic aug now!\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m223\u001b[0m - \u001b[1m--->Add additional L1 loss now!\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m270\u001b[0m - \u001b[1mepoch: 6/10, iter: 10/18, gpu mem: 13692Mb, mem: 3.3Gb, iter_time: 0.207s, data_time: 0.004s, total_loss: nan, iou_loss: 5.0, l1_loss: nan, conf_loss: 6.5, cls_loss: 0.0, lr: 6.250e-05, size: 640, ETA: 0:00:27\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m402\u001b[0m - \u001b[1mSave weights to ./YOLOX_outputs/yolox_drone\u001b[0m\n",
            "100% 4/4 [00:00<00:00,  5.81it/s]\n",
            "\u001b[32m2025-05-08 14:16:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.evaluators.coco_evaluator\u001b[0m:\u001b[36m259\u001b[0m - \u001b[1mEvaluate in main process...\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m381\u001b[0m - \u001b[1m\n",
            "Average forward time: 7.44 ms, Average NMS time: 0.38 ms, Average inference time: 7.82 ms\n",
            "\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m402\u001b[0m - \u001b[1mSave weights to ./YOLOX_outputs/yolox_drone\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m402\u001b[0m - \u001b[1mSave weights to ./YOLOX_outputs/yolox_drone\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m218\u001b[0m - \u001b[1m---> start train epoch7\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m221\u001b[0m - \u001b[1m--->No mosaic aug now!\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m223\u001b[0m - \u001b[1m--->Add additional L1 loss now!\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m270\u001b[0m - \u001b[1mepoch: 7/10, iter: 10/18, gpu mem: 13692Mb, mem: 3.3Gb, iter_time: 0.420s, data_time: 0.007s, total_loss: nan, iou_loss: 5.0, l1_loss: nan, conf_loss: 6.8, cls_loss: 0.0, lr: 6.250e-05, size: 704, ETA: 0:00:21\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m402\u001b[0m - \u001b[1mSave weights to ./YOLOX_outputs/yolox_drone\u001b[0m\n",
            "100% 4/4 [00:00<00:00,  5.66it/s]\n",
            "\u001b[32m2025-05-08 14:16:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.evaluators.coco_evaluator\u001b[0m:\u001b[36m259\u001b[0m - \u001b[1mEvaluate in main process...\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m381\u001b[0m - \u001b[1m\n",
            "Average forward time: 7.71 ms, Average NMS time: 0.31 ms, Average inference time: 8.02 ms\n",
            "\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m402\u001b[0m - \u001b[1mSave weights to ./YOLOX_outputs/yolox_drone\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m402\u001b[0m - \u001b[1mSave weights to ./YOLOX_outputs/yolox_drone\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m218\u001b[0m - \u001b[1m---> start train epoch8\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m221\u001b[0m - \u001b[1m--->No mosaic aug now!\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m223\u001b[0m - \u001b[1m--->Add additional L1 loss now!\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m270\u001b[0m - \u001b[1mepoch: 8/10, iter: 10/18, gpu mem: 13692Mb, mem: 3.2Gb, iter_time: 0.347s, data_time: 0.004s, total_loss: nan, iou_loss: 5.0, l1_loss: nan, conf_loss: 6.5, cls_loss: 0.0, lr: 6.250e-05, size: 736, ETA: 0:00:15\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m402\u001b[0m - \u001b[1mSave weights to ./YOLOX_outputs/yolox_drone\u001b[0m\n",
            "100% 4/4 [00:00<00:00,  6.14it/s]\n",
            "\u001b[32m2025-05-08 14:16:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.evaluators.coco_evaluator\u001b[0m:\u001b[36m259\u001b[0m - \u001b[1mEvaluate in main process...\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m381\u001b[0m - \u001b[1m\n",
            "Average forward time: 8.49 ms, Average NMS time: 0.44 ms, Average inference time: 8.94 ms\n",
            "\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m402\u001b[0m - \u001b[1mSave weights to ./YOLOX_outputs/yolox_drone\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m402\u001b[0m - \u001b[1mSave weights to ./YOLOX_outputs/yolox_drone\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m218\u001b[0m - \u001b[1m---> start train epoch9\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m221\u001b[0m - \u001b[1m--->No mosaic aug now!\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m223\u001b[0m - \u001b[1m--->Add additional L1 loss now!\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m270\u001b[0m - \u001b[1mepoch: 9/10, iter: 10/18, gpu mem: 13692Mb, mem: 3.3Gb, iter_time: 0.312s, data_time: 0.006s, total_loss: nan, iou_loss: 5.0, l1_loss: nan, conf_loss: 5.8, cls_loss: 0.0, lr: 6.250e-05, size: 736, ETA: 0:00:08\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m402\u001b[0m - \u001b[1mSave weights to ./YOLOX_outputs/yolox_drone\u001b[0m\n",
            "100% 4/4 [00:00<00:00,  5.62it/s]\n",
            "\u001b[32m2025-05-08 14:16:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.evaluators.coco_evaluator\u001b[0m:\u001b[36m259\u001b[0m - \u001b[1mEvaluate in main process...\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m381\u001b[0m - \u001b[1m\n",
            "Average forward time: 8.13 ms, Average NMS time: 0.34 ms, Average inference time: 8.46 ms\n",
            "\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m402\u001b[0m - \u001b[1mSave weights to ./YOLOX_outputs/yolox_drone\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m402\u001b[0m - \u001b[1mSave weights to ./YOLOX_outputs/yolox_drone\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m218\u001b[0m - \u001b[1m---> start train epoch10\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m221\u001b[0m - \u001b[1m--->No mosaic aug now!\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m223\u001b[0m - \u001b[1m--->Add additional L1 loss now!\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m270\u001b[0m - \u001b[1mepoch: 10/10, iter: 10/18, gpu mem: 13692Mb, mem: 3.3Gb, iter_time: 0.192s, data_time: 0.005s, total_loss: nan, iou_loss: 5.0, l1_loss: nan, conf_loss: 3.6, cls_loss: 0.0, lr: 6.250e-05, size: 608, ETA: 0:00:02\u001b[0m\n",
            "\u001b[32m2025-05-08 14:16:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m402\u001b[0m - \u001b[1mSave weights to ./YOLOX_outputs/yolox_drone\u001b[0m\n",
            "100% 4/4 [00:00<00:00,  5.72it/s]\n",
            "\u001b[32m2025-05-08 14:17:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.evaluators.coco_evaluator\u001b[0m:\u001b[36m259\u001b[0m - \u001b[1mEvaluate in main process...\u001b[0m\n",
            "\u001b[32m2025-05-08 14:17:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m381\u001b[0m - \u001b[1m\n",
            "Average forward time: 7.89 ms, Average NMS time: 0.40 ms, Average inference time: 8.29 ms\n",
            "\u001b[0m\n",
            "\u001b[32m2025-05-08 14:17:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m402\u001b[0m - \u001b[1mSave weights to ./YOLOX_outputs/yolox_drone\u001b[0m\n",
            "\u001b[32m2025-05-08 14:17:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m402\u001b[0m - \u001b[1mSave weights to ./YOLOX_outputs/yolox_drone\u001b[0m\n",
            "\u001b[32m2025-05-08 14:17:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m200\u001b[0m - \u001b[1mTraining of experiment is done and the best AP is 0.00\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}